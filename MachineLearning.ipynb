{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.sql.functions import *\n\n#spark=SparkSession.builder.master(\"local\").setApp(\"Linear Regression Example\").getOrCreate()\n\ndf=spark.read.format(\"csv\").options(inferSchema=\"true\",header=\"true\").load(\"/FileStore/tables/Linear_regression_dataset.csv\")\nprint(df.show())\nprint(\"Getting the Shape of the Data\")\nprint(\"Num of Rows:{0} Num of Columns:{1}\".format(df.count(), len(df.columns)))\nprint(\"\\nViewing the Schema of the Data\")\nprint(df.printSchema)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+-----+-----+-----+-----+\nvar_1|var_2|var_3|var_4|var_5|label|\n+-----+-----+-----+-----+-----+-----+\n  734|  688|   81|0.328|0.259|0.418|\n  700|  600|   94| 0.32|0.247|0.389|\n  712|  705|   93|0.311|0.247|0.417|\n  734|  806|   69|0.315| 0.26|0.415|\n  613|  759|   61|0.302| 0.24|0.378|\n  748|  676|   85|0.318|0.255|0.422|\n  669|  588|   97|0.315|0.251|0.411|\n  667|  845|   68|0.324|0.251|0.381|\n  758|  890|   64| 0.33|0.274|0.436|\n  726|  670|   88|0.335|0.268|0.422|\n  583|  794|   55|0.302|0.236|0.371|\n  676|  746|   72|0.317|0.265|  0.4|\n  767|  699|   89|0.332|0.274|0.433|\n  637|  597|   86|0.317|0.252|0.374|\n  609|  724|   69|0.308|0.244|0.382|\n  776|  733|   83|0.325|0.259|0.437|\n  701|  832|   66|0.325| 0.26| 0.39|\n  650|  709|   74|0.316|0.249|0.386|\n  804|  668|   95|0.337|0.265|0.453|\n  713|  614|   94| 0.31|0.238|0.404|\n+-----+-----+-----+-----+-----+-----+\nonly showing top 20 rows\n\nNone\nGetting the Shape of the Data\nNum of Rows:1232 Num of Columns:6\n\nViewing the Schema of the Data\n&lt;bound method DataFrame.printSchema of DataFrame[var_1: int, var_2: int, var_3: int, var_4: double, var_5: double, label: double]&gt;\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["print(\"\\nViewing the Statistics of the Table\")\nprint(df.describe().show())\n\nprint(\"Determing Co-Relation between Input and Output Columns\")\nprint(\"Correlation between var_1 and label : {0}\".format(df.select(corr('var_1','label')).show()))\nprint(\"Correlation between var_2 and label : {0}\".format(df.select(corr('var_2','label')).show()))\nprint(\"Correlation between var_3 and label : {0}\".format(df.select(corr('var_3', 'label')).show()))\nprint(\"Correlation between var_4 and label : {0}\".format(df.select(corr('var_4', 'label')).show()))\nprint(\"Correlation between var_5 and label : {0}\".format(df.select(corr('var_5', 'label')).show()))\t  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nViewing the Statistics of the Table\n+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\nsummary|            var_1|            var_2|             var_3|               var_4|               var_5|              label|\n+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n  count|             1232|             1232|              1232|                1232|                1232|               1232|\n   mean|715.0819805194806|715.0819805194806| 80.90422077922078|  0.3263311688311693| 0.25927272727272715|0.39734172077922014|\n stddev| 91.5342940441652|93.07993263118064|11.458139049993724|0.015012772334166148|0.012907228928000298|0.03326689862173776|\n    min|              463|              472|                40|               0.277|               0.214|              0.301|\n    max|             1009|             1103|               116|               0.373|               0.294|              0.491|\n+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n\nNone\nDeterming Co-Relation between Input and Output Columns\n+------------------+\ncorr(var_1, label)|\n+------------------+\n0.9187399607627283|\n+------------------+\n\nCorrelation between var_1 and label : None\n+-------------------+\n corr(var_2, label)|\n+-------------------+\n0.43652698913681093|\n+-------------------+\n\nCorrelation between var_2 and label : None\n+------------------+\ncorr(var_3, label)|\n+------------------+\n0.4014958408311139|\n+------------------+\n\nCorrelation between var_3 and label : None\n+------------------+\ncorr(var_4, label)|\n+------------------+\n0.7909100204842113|\n+------------------+\n\nCorrelation between var_4 and label : None\n+------------------+\ncorr(var_5, label)|\n+------------------+\n0.7904806260381185|\n+------------------+\n\nCorrelation between var_5 and label : None\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Feature Engineering\n# This is the part where we combine all our input features into a Single Vector using Spark's VectorAssembler\n# It creates only a single feature that captures the input values for that Row\n# Hence instead of 5 Input Columns it essentially merges all input columns into a Single Feature Vector Column\n\nfrom pyspark.ml.linalg import Vector\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n# We can select the list of the Columns that are to be assembled within the Vector and can pass only those columns to VectorAssembler\nprint(df.columns)\n\n# Creating a VectorAssembler object by passing the required Input Features\nvec_assembler=VectorAssembler(inputCols=['var_1','var_2','var_3','var_4','var_5'],outputCol='features')\n# Applying the created vec_assembler over our Input DataFrame by calling transform function\nfeatures_df=vec_assembler.transform(df)\nprint(features_df.printSchema())\nprint(features_df.show(truncate=False))\n# One Additional column named \"features\" that contains single Dense Vector for all of the inputs\nprint(features_df.select(\"features\").show(truncate=False))\n\n\n\n\n      "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;var_1&#39;, &#39;var_2&#39;, &#39;var_3&#39;, &#39;var_4&#39;, &#39;var_5&#39;, &#39;label&#39;]\nroot\n-- var_1: integer (nullable = true)\n-- var_2: integer (nullable = true)\n-- var_3: integer (nullable = true)\n-- var_4: double (nullable = true)\n-- var_5: double (nullable = true)\n-- label: double (nullable = true)\n-- features: vector (nullable = true)\n\nNone\n+-----+-----+-----+-----+-----+-----+------------------------------+\nvar_1|var_2|var_3|var_4|var_5|label|features                      |\n+-----+-----+-----+-----+-----+-----+------------------------------+\n734  |688  |81   |0.328|0.259|0.418|[734.0,688.0,81.0,0.328,0.259]|\n700  |600  |94   |0.32 |0.247|0.389|[700.0,600.0,94.0,0.32,0.247] |\n712  |705  |93   |0.311|0.247|0.417|[712.0,705.0,93.0,0.311,0.247]|\n734  |806  |69   |0.315|0.26 |0.415|[734.0,806.0,69.0,0.315,0.26] |\n613  |759  |61   |0.302|0.24 |0.378|[613.0,759.0,61.0,0.302,0.24] |\n748  |676  |85   |0.318|0.255|0.422|[748.0,676.0,85.0,0.318,0.255]|\n669  |588  |97   |0.315|0.251|0.411|[669.0,588.0,97.0,0.315,0.251]|\n667  |845  |68   |0.324|0.251|0.381|[667.0,845.0,68.0,0.324,0.251]|\n758  |890  |64   |0.33 |0.274|0.436|[758.0,890.0,64.0,0.33,0.274] |\n726  |670  |88   |0.335|0.268|0.422|[726.0,670.0,88.0,0.335,0.268]|\n583  |794  |55   |0.302|0.236|0.371|[583.0,794.0,55.0,0.302,0.236]|\n676  |746  |72   |0.317|0.265|0.4  |[676.0,746.0,72.0,0.317,0.265]|\n767  |699  |89   |0.332|0.274|0.433|[767.0,699.0,89.0,0.332,0.274]|\n637  |597  |86   |0.317|0.252|0.374|[637.0,597.0,86.0,0.317,0.252]|\n609  |724  |69   |0.308|0.244|0.382|[609.0,724.0,69.0,0.308,0.244]|\n776  |733  |83   |0.325|0.259|0.437|[776.0,733.0,83.0,0.325,0.259]|\n701  |832  |66   |0.325|0.26 |0.39 |[701.0,832.0,66.0,0.325,0.26] |\n650  |709  |74   |0.316|0.249|0.386|[650.0,709.0,74.0,0.316,0.249]|\n804  |668  |95   |0.337|0.265|0.453|[804.0,668.0,95.0,0.337,0.265]|\n713  |614  |94   |0.31 |0.238|0.404|[713.0,614.0,94.0,0.31,0.238] |\n+-----+-----+-----+-----+-----+-----+------------------------------+\nonly showing top 20 rows\n\nNone\n+------------------------------+\nfeatures                      |\n+------------------------------+\n[734.0,688.0,81.0,0.328,0.259]|\n[700.0,600.0,94.0,0.32,0.247] |\n[712.0,705.0,93.0,0.311,0.247]|\n[734.0,806.0,69.0,0.315,0.26] |\n[613.0,759.0,61.0,0.302,0.24] |\n[748.0,676.0,85.0,0.318,0.255]|\n[669.0,588.0,97.0,0.315,0.251]|\n[667.0,845.0,68.0,0.324,0.251]|\n[758.0,890.0,64.0,0.33,0.274] |\n[726.0,670.0,88.0,0.335,0.268]|\n[583.0,794.0,55.0,0.302,0.236]|\n[676.0,746.0,72.0,0.317,0.265]|\n[767.0,699.0,89.0,0.332,0.274]|\n[637.0,597.0,86.0,0.317,0.252]|\n[609.0,724.0,69.0,0.308,0.244]|\n[776.0,733.0,83.0,0.325,0.259]|\n[701.0,832.0,66.0,0.325,0.26] |\n[650.0,709.0,74.0,0.316,0.249]|\n[804.0,668.0,95.0,0.337,0.265]|\n[713.0,614.0,94.0,0.31,0.238] |\n+------------------------------+\nonly showing top 20 rows\n\nNone\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.linalg import Vector\nfrom pyspark.ml.feature import VectorAssembler\n\n# Now we can take only the features column (DenseVector containing our Input Features) and ouput Column and create a Separate DataFrame\nmodel_df=features_df.select(\"features\",\"label\")\nprint(model_df.show(truncate=False))\nprint(\"Checking the Shape of the Model DataSet\")\nprint(\"Num. of Rows: {0} Num. of Columns: {1}\".format(model_df.count(), len(model_df.columns)))\n# STEP_5 Splitting the DataSet (Apply randomSplit() function)\n\"\"\"We have to split out DataSet into training and test dataset in order to train and evaluate the Performance of Linear Regression Model \nWe Split it into 70%, 30% ratio to train our Model on 70% of the DataSet. \"\"\"\ntrain_df,test_df=model_df.randomSplit([0.7,0.3])      \n\nprint(\"Printing Shape of Training and test DataSets\")\nprint(\"Training DataSet\")\nprint(\"Num of Rows: {0} Num. of Columns: {1}\".format(train_df.count(),len(train_df.columns)))\nprint(\"Test DataSet\")\nprint(\"Num of Rows: {0} Num. of Columns: {1}\".format(test_df.count(),len(test_df.columns)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------+-----+\nfeatures                      |label|\n+------------------------------+-----+\n[734.0,688.0,81.0,0.328,0.259]|0.418|\n[700.0,600.0,94.0,0.32,0.247] |0.389|\n[712.0,705.0,93.0,0.311,0.247]|0.417|\n[734.0,806.0,69.0,0.315,0.26] |0.415|\n[613.0,759.0,61.0,0.302,0.24] |0.378|\n[748.0,676.0,85.0,0.318,0.255]|0.422|\n[669.0,588.0,97.0,0.315,0.251]|0.411|\n[667.0,845.0,68.0,0.324,0.251]|0.381|\n[758.0,890.0,64.0,0.33,0.274] |0.436|\n[726.0,670.0,88.0,0.335,0.268]|0.422|\n[583.0,794.0,55.0,0.302,0.236]|0.371|\n[676.0,746.0,72.0,0.317,0.265]|0.4  |\n[767.0,699.0,89.0,0.332,0.274]|0.433|\n[637.0,597.0,86.0,0.317,0.252]|0.374|\n[609.0,724.0,69.0,0.308,0.244]|0.382|\n[776.0,733.0,83.0,0.325,0.259]|0.437|\n[701.0,832.0,66.0,0.325,0.26] |0.39 |\n[650.0,709.0,74.0,0.316,0.249]|0.386|\n[804.0,668.0,95.0,0.337,0.265]|0.453|\n[713.0,614.0,94.0,0.31,0.238] |0.404|\n+------------------------------+-----+\nonly showing top 20 rows\n\nNone\nChecking the Shape of the Model DataSet\nNum. of Rows: 1232 Num. of Columns: 2\nPrinting Shape of Training and test DataSets\nTraining DataSet\nNum of Rows: 871 Num. of Columns: 2\nTest DataSet\nNum of Rows: 361 Num. of Columns: 2\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# STEP_6: Build and Train Linear Regression Model  (fit(train_df) method of pyspark.ml.regression.LinearRegression)\n                                                    model.evaluate(train_df) -> Apply the developed model over the train DataFrame\n                                                    modelPrediction1.r2 ->  Retrieve the accuracy % of the model based of training Data\n                                                    model.evaluate(test_df) -> Apply the developed  model over the test DataFrame\n                                                    modelPrediction2.r2 -> Retrieve the Accuracy % of model based of test Data\n                                                    modelPrediction2.meanSquaredError -> Compute the accuracy of the Model \n\"\"\"\nIn this step we build and train the Linear Regression Model using Features of the Input and Output Columns\nWe can fetch the Co-efficients (B1, B2, B3, B4, B5) for each of the Features and Intercept (B0) values of the model as well\nWe can also evaluate the Performance of the Model on Training Data as well using r2. \n\"\"\"\n\nfrom pyspark.ml.regression import LinearRegression\nlin_Reg=LinearRegression(labelCol=\"label\")\n\nlr_model=lin_Reg.fit(train_df)\nprint(lr_model.coefficients)\nprint(lr_model.intercept)\n# Evaluating the Model on the Training DataSet\ntraining_predictions=lr_model.evaluate(train_df)\n# Fetching the accuracy of the Model on Training Data\nprint(training_predictions.r2)\n\n# STEP_7: Evaluate Linear Regression Model on Test Data ()\n# Evaluating the Model on Test DataSet\ntest_predictions=lr_model.evaluate(test_df)\n# Checking the accuracy of the Model in Test Dataset\nprint(test_predictions.r2)\n# Compute the mean Squared Error \nprint(\"Mean Squared Error: {0}\".format(test_predictions.meanSquaredError))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[0.0003494946241817967,4.056115804179784e-05,7.21809797297416e-05,-0.6577943619985317,0.553093216121237]\n0.18406129130733442\n0.8757714672991658\n0.8507603050705955\n0.00016073444609295714\n</div>"]}}],"execution_count":5}],"metadata":{"name":"MachineLearning","notebookId":1983580502630379},"nbformat":4,"nbformat_minor":0}
